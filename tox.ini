[tox]
envlist = test
isolated_build = true
skip_missing_interpreters = true
minversion = 3.14
requires = virtualenv >= 20.0.34


[testenv]
description = An environment designed to facilitate testing (running the test suite)
passenv = *
setenv =
# It will overide variables in passenv in case of collision
    PYTHONPATH = {toxinidir}{/}tests
    PYTHONBUFFERED = yes
    TEST_RESULTS_DIR = {toxinidir}{/}test-results
    MYPYPATH = {toxinidir}{/}src{/}stubs
    PY_PACKAGE = cicd_test_workflow
    DIST_DIR = dist
    COVERAGE_FILE = {toxworkdir}{/}.coverage.{envname}
    TEST_STATUS_DIR = {envtmpdir}
    PYPY3323BUG = 1
    black,lint,isort: LINT_ARGS = "src tests scripts"
    DEFAULT_REQS_FILE = reqs.txt
commands =
    pytest -ra --cov --cov-report=term-missing \
      --cov-report=html:{envdir}/htmlcov --cov-context=test \
      --cov-report=xml:{toxworkdir}/coverage.{envname}.xml \
      {posargs:-n auto} tests

# DEPS_OVER= tox -e pin-deps && tox -e test
[testenv:test]
basepython = {env:TOXPYTHON:python3}
skip_install = true
deps = -r {env:DEFAULT_REQS_FILE}
commands = pytest -ra {posargs:-n auto -vvs} tests


[testenv:dev]
basepython = {env:TOXPYTHON:python3}
usedevelop = true
commands = pytest -ra {posargs:-n auto -vvs} tests


# CODE LINTING, STATIC (STYLE) CHECKING

[testenv:black]
description = black ops
deps = black
skip_install = true
changedir = {toxinidir}
commands = black {posargs:{env:APPLY_BLACK:--check}} \
    --skip-string-normalization \
    --config pyproject.toml "{env:LINT_ARGS:.}"


[testenv:isort]
description = isort
deps = isort >= 5.0.0
skip_install = true
changedir = {toxinidir}
commands = isort \
    {posargs:{env:APPLY_ISORT:--check}} \
    "{env:LINT_ARGS:.}"

[testenv:pylint]
description = Run the Pylint tool to analyse the Python code and output
    information about errors, potential problems and convention violations
deps =
    pylint ; python_version == '3.11'
    pylint == 2.7.4 ; python_version < '3.11'
usedevelop = true
changedir = {toxinidir}
commands =
    - python -m pylint src{/}{env:PY_PACKAGE}
    - python -m pylint tests

[testenv:prospector]
description = Run multiple static code analysis tools defined in .prospector.yml
deps = prospector[with_pyroma] == 1.3.1
skip_install = true
changedir = {toxinidir}
commands_pre =
    python -c 'import os; f = ".pylintrc"; exec("if os.path.exists(f):\n    os.rename(f, \".pylintrc-bak\")")'
commands =
    prospector src
    prospector tests
commands_post =
    python -c 'import os; f = ".pylintrc-bak"; exec("if os.path.exists(f):\n    os.rename(f, \".pylintrc\")")'


[testenv:pin-deps]
description = Pin dependencies from poetry lock. Use the REQS_FILE var to override default
    generated requirements file path (default inherited from testenv: reqs-pinned.txt).
    By default does NOT add Extras, but only the required dependencies (from pyproject).
    Eg `tox -e pin-deps` adds only the "prod"/required dependencies.
    Eg `tox -e pin-deps -- -E docs` adds production (root) and 'docs' Extra dependencies.
    Eg `REQS_FILE=reqs-test.txt tox -e pin-deps`
basepython = {env:TOXPYTHON:python3}
passenv =
    REQS_FILE
    DEPS_OVER
skip_install = true
deps =
    poetry
    poetry-plugin-export
commands =
    python -m poetry export -f requirements.txt -o {env:REQS_FILE:{env:DEFAULT_REQS_FILE}} {posargs}
    python -c 'print( "\n  Generated requirements file: " + "{env:REQS_FILE:{env:DEFAULT_REQS_FILE}}" );'



### PYTHON PACKAGING ###
[testenv:build]
description = Create a source and wheel distribution.
    Creates .tar.gz and .whl files in the {env:DIST_DIR} folder, that can be upload to a pypi index server.
basepython = {env:TOXPYTHON:python3}
deps = build
skip_install = true
changedir = {toxinidir}
commands_pre =
    python -c 'import os; import shutil; d = "{env:DIST_DIR}"; exec("if os.path.exists(d):\n    shutil.rmtree(d)");'
commands = python -m build {toxinidir} --outdir {env:DIST_DIR}


### PYPI ###
[testenv:deploy]
# In CI, set PACKAGE_DIST_VERSION, TWINE_USERNAME, TWINE_PASSWROD, and PYPI_SERVER
# then run, failing if existing found: tox -s false -vv -e deploy -- upload --non-interactive
# then run, allowing existing: tox -s false -vv -e deploy -- upload --non-interactive --skip-existing

# Deploy to test.pypi.org : TWINE_USERNAME=user TWINE_PASSWROD=pass PACKAGE_DIST_VERSION=1.0.0 tox -e deploy
# Deploy to pypi.org      : TWINE_USERNAME=user TWINE_PASSWROD=pass PACKAGE_DIST_VERSION=1.0.0 PYPI_SERVER=pypi tox -e deploy
description = Deploy the python package to be hosted in a pypi server. Requires to authenticate with the pypi
    server, so please set the TWINE_PASSWORD and TWINE_PASSWORD environment variables.
    Also, requires the PACKAGE_DIST_VERSION variable to explicitly indicate which distribution
    (semantic version: ie 0.5.3, 1.0.0) we intent to deploy/upload. That way we avoid unintentionally deploying
    a wrong version and we make sure that the correct version is released to pypi. By default, deploys to a
    pypi 'test server', currently at test.pypi.org. If you want to deploy to the "production" pypi (at pypi.org),
    then you have to set the PYPI_SERVER environment variable to 'pypi', like `export PYPI_SERVER=pypi`.
    Before deploying, certain sanity checks are ran on the distribution artefacts (ie .tar.gz, .whl) to be uploaded.
passenv =
    PACKAGE_DIST_VERSION
    TWINE_USERNAME
    TWINE_PASSWORD
deps =
    keyring==21.3.0
    twine==3.4.0
skip_install = true
commands_pre =
    python -c 'import os; n = "TWINE_USERNAME"; v = os.environ.get(n); exec("if not v:\n    print(\"Please set the \" + str(n) + \" variable.\")\n    exit(1)");'
    python -c 'import os; n = "TWINE_PASSWORD"; v = os.environ.get(n); exec("if not v:\n    print(\"Please set the \" + str(n) + \" variable.\")\n    exit(1)");'
    python -c 'import os; n = "PACKAGE_DIST_VERSION"; v = os.environ.get(n); exec("if not v:\n    print(\"Please set the \" + str(n) + \" variable.\")\n    exit(1)");'
    python -c 'import os; n = "PYPI_SERVER"; exec("if n in os.environ:\n    v = os.environ[n]\n    if v != \"pypi\":\n        print(\"Environment variable PYPI_SERVER detected, but was not set to pypi. Please set to pypi or run tox -e deploy from an environment where the PYPI_SERVER variable is NOT present at all.\")\n        exit(1)");'
    python -m twine check {env:DIST_DIR}/{env:PY_PACKAGE}-{env:PACKAGE_DIST_VERSION:MISSMATCHED_PACKAGE_DIST_VERSION_ERROR}*
commands =
    twine {posargs:upload --non-interactive} --repository {env:PYPI_SERVER:testpypi --skip-existing} {env:DIST_DIR}{/}{env:PY_PACKAGE}-{env:PACKAGE_DIST_VERSION:MISSMATCHED_PACKAGE_DIST_VERSION_ERROR}* --verbose


## PYDEPS: IMPORTS/CODE VISUALIZATION ##
[testenv:pydeps]
description =
    Visualise Python dependency graphs (roughly which module imports which) and store in .svg file(s).
    Eg: `tox -e pydeps`, `PYDEPS_DIR=my-destination-dir tox -e pydeps`.
    PYDEPS_DIR controls the relative location (to your current working dir) of the target dir to store
    the generated files. The default target dir is 'pydeps'. Dir is created if it doesn't exist.
    Requires the 'dot' executable to be in your PATH. Installing the graphviz library should make
    the dot executable available in your PATH. Installing 'graphviz':
    * For Linux, please run "sudo apt install graphviz"
    * For MacOS, please run "brew install graphviz"
basepython = {env:TOXPYTHON:python3.10}
passenv =
    HOME
    PWD
    PYDEPS_DIR
deps = pydeps==1.11.0
usedevelop = true
commands_pre =
    python -c 'from pathlib import Path; import os; p = Path(os.environ["PWD"]) / os.getenv("PYDEPS_DIR", "pydeps"); p.mkdir(parents=True, exist_ok=True);'
commands =
    pydeps --version

    # --max-bacon : exclude nodes that are more than n hops away
    # (default=2, 0 -> infinite)

    # --min-cluster-size : the minimum number of nodes a dependency must have before being clustered (default=0)

    # --max-cluster-size : the maximum number of nodes a dependency can have before the cluster is collapsed to a single node (default=0)
    # --keep-target-cluster : draw target module as a cluster

    # Draw only the source code package inner dependencies
    pydeps src{/}{env:PY_PACKAGE} --only {env:PY_PACKAGE} --noshow -o {env:PWD}{/}{env:PYDEPS_DIR:pydeps}{/}deps_inner.svg
    ; # Draw the source code package inner and external dependencies
    pydeps src{/}{env:PY_PACKAGE} --cluster --noshow -o {env:PWD}{/}{env:PYDEPS_DIR:pydeps}{/}deps_all.svg

    ; # Visualize the package inner dependencies and abstract the external (eg with numpy, pandas, etc) ones
    ; # Draw the source code package inner and minimum external dependencies
    pydeps src{/}{env:PY_PACKAGE} --max-cluster-size=2 --keep-target-cluster --noshow -o {env:PWD}{/}{env:PYDEPS_DIR:pydeps}{/}deps_ktc-mcs_2.svg

    ; # Draw the source code package inner and all external dependencies
    pydeps src{/}{env:PY_PACKAGE} --keep-target-cluster --noshow -o {env:PWD}{/}{env:PYDEPS_DIR:pydeps}{/}deps_ktc.svg

    python -c 'from pathlib import Path; p = Path("{env:PWD}{/}{env:PYDEPS_DIR:pydeps}"); print(f"\nGenerated .svg files in \"\{str(p.absolute())\}\".");'